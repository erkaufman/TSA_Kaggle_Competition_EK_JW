---
title: "Forecasting Competition"
author: "Emma Kaufman and Jaime Wargo"
date: "2024-04-26"
output: pdf_document
---
```{r package, message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(readxl)
library(here)
```

```{r}
load <- read_excel("Data_TOPOST/load.xlsx")
relative_humidity <- read_excel("Data_TOPOST/relative_humidity.xlsx")
temperature <- read_excel("Data_TOPOST/temperature.xlsx")
```

## WRANGLE/PROCESS THE DATASET

```{r}
#start with wrangling load data
load_all <- load %>% 
  pivot_longer(cols = h1:h24) %>% 
  rename(Hour = name,
         Load= value) %>% 
  mutate(Hour= as.numeric(gsub('h','', Hour))-1) %>% 
  mutate(date= ymd(date)) %>% 
  mutate(Day = day(date),
         Month= month(date),
         Year= year(date)) %>% 
  select(meter_id, date, Year, Month, Day, Hour, Load)

#check for NAs
summary(load_all$Load)

```

```{r}
#Creating a data frame with daily observations
load_daily <- load_all %>% 
  filter( !is.na(Load) ) %>% 
  group_by(meter_id, date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  summarise( Daily_mean_load = mean(Load)) #take the mean for the day

ggplot(load_daily, aes(x=date,y=Daily_mean_load)) +
  geom_line() +
  ylab("Average Daily Load")

#check for NAs
summary(load_daily$Daily_mean_load)
```

```{r}
#temperature and relative humidity data
temperature_all <- temperature %>% 
  mutate(date= ymd(date)) %>% 
  mutate(Day= day(date),
          Month= month(date),
          Year= year(date)) %>% 
  mutate(hr= hr-1) %>% 
  rename(hour= hr) 

relative_humidity_all <- relative_humidity %>% 
   mutate(date= ymd(date)) %>% 
  mutate(Day= day(date),
          Month= month(date),
          Year= year(date)) %>% 
  mutate(hr= hr-1) %>% 
  rename(hour= hr)

#check for NA
summary(temperature_all)
summary(relative_humidity_all)

#summarize daily data
temp_daily <- temperature_all %>% 
  group_by(date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  #daily mean for each station
  summarise_at(vars(matches("^t_ws[1-9]|^t_ws1[0-8]$")), list(Daily_temp = ~mean(., na.rm = TRUE)))
 

rh_daily <- relative_humidity_all %>% 
  group_by(date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  #daily mean for each station
  summarise_at(vars(matches("^rh_ws[1-9]|^rh_ws1[0-8]$")), list(Daily_temp = ~mean(., na.rm = TRUE)))

```

```{r}
#save datasets

write.csv(load_daily,file=here("Data","Processed","Daily_Load.csv"))
write.csv(temp_daily,file=here("Data","Processed","Daily_Temp.csv"))
write.csv(rh_daily,file=here("Data","Processed","Daily_Relative_Humidity.csv"))
```

## CREATE A TIME SERIES OBJECT

```{r}
#load time series object
ts_load_daily <- msts(load_daily$Daily_mean_load, #daily data frame mean
                           seasonal.periods =c(7,365.25), #seasonal periods
                           start=c(2005,1,1))
```

```{r}
#decomposition of daily data
ts_load_daily %>% mstl() %>%
  autoplot()
```

## CREATING TEST AND TRAINING DATASETS (YEAR AND MONTH)

```{r}
#training and test datasets

#create a subset for training purpose (try forecasting for one month!)
n_for = 365
ts_daily_train <- subset(ts_load_daily,
                                   end = length(ts_load_daily)-n_for)

#create a subset for testing purpose
ts_daily_test <- subset(ts_load_daily,
                                   start = length(ts_load_daily)-n_for)

#test is just a month
ts_daily_train_month <- subset(ts_load_daily,
                                   end = length(ts_load_daily)-30)

#create a subset for testing purpose
ts_daily_test_month <- subset(ts_load_daily,
                                   start = length(ts_load_daily)-30)
```

```{r}
#plotting these test and train data
autoplot(ts_daily_train)
autoplot(ts_daily_test)
```

## FITTING AND FORECASTING MODELS

### ETS
```{r}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_daily_train,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Load")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Load")

#alternative coding if you don't need to save the objects
#ts_act_power_daily_train %>% stlf(h=365) %>% autoplot() 
#very easy to read/run/implement 
#but you don't have anything stored on your environment

#trying with just the month test set as opposed to year

ETS_fit_2 <-  stlf(ts_daily_train_month,h=30)

#Plot foresting results
autoplot(ETS_fit_2) + ylab("Load")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ETS_fit_2, series="STL + ETS",PI=FALSE) +
  ylab("Active Load")
```
```{r}
ETS_scores <- accuracy(ETS_fit$mean,ts_daily_test)

ETS_scores_2 <- accuracy(ETS_fit_2$mean,ts_daily_test_month)

```

### Arima and Fourier
```{r}
ARIMA_Four_fit <- auto.arima(ts_daily_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_daily_train, 
                                          K=c(2,4))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_daily_train,
                                        K=c(2,4),
                                        h=365), h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Load")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Load")
```

```{r}
#Model 2: ARIMA + Fourier 
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_daily_test)
```

```{r}
# adding results from ETS_fit to submission template
submission_ETS <- read_csv("output/submission_template.csv", 
    col_types = cols(load = col_number()))

submission_ETS$load <- ETS_fit$fitted[2312:2342]


#creating .csv output
write.csv(submission_ETS,file=here("output","Submission1_EK_JW.csv"))
```


