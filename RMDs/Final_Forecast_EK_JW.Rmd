---
title: "Forecasting Competition"
author: "Emma Kaufman and Jaime Wargo"
date: "2024-04-26"
output: pdf_document
---
```{r package, message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(readxl)
library(here)
```

```{r}
load <- read_excel("Data_TOPOST/load.xlsx")
relative_humidity <- read_excel("Data_TOPOST/relative_humidity.xlsx")
temperature <- read_excel("Data_TOPOST/temperature.xlsx")
```

## WRANGLE/PROCESS THE DATASET

```{r}
#start with wrangling load data
load_all <- load %>% 
  pivot_longer(cols = h1:h24) %>% 
  rename(Hour = name,
         Load= value) %>% 
  mutate(Hour= as.numeric(gsub('h','', Hour))-1) %>% 
  mutate(date= ymd(date)) %>% 
  mutate(Day = day(date),
         Month= month(date),
         Year= year(date)) %>% 
  select(meter_id, date, Year, Month, Day, Hour, Load)

#check for NAs
summary(load_all$Load)

```

```{r}
#Creating a data frame with daily observations
load_daily <- load_all %>% 
  filter( !is.na(Load) ) %>% 
  group_by(meter_id, date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  summarise( Daily_mean_load = mean(Load)) #take the mean for the day

ggplot(load_daily, aes(x=date,y=Daily_mean_load)) +
  geom_line() +
  ylab("Average Daily Load")

#check for NAs
summary(load_daily$Daily_mean_load)
```

```{r}
#temperature and relative humidity data
temperature_all <- temperature %>% 
  mutate(date= ymd(date)) %>% 
  mutate(Day= day(date),
          Month= month(date),
          Year= year(date)) %>% 
  mutate(hr= hr-1) %>% 
  rename(hour= hr) 

relative_humidity_all <- relative_humidity %>% 
   mutate(date= ymd(date)) %>% 
  mutate(Day= day(date),
          Month= month(date),
          Year= year(date)) %>% 
  mutate(hr= hr-1) %>% 
  rename(hour= hr)

#check for NA
summary(temperature_all)
summary(relative_humidity_all)

#summarize daily data
temp_daily <- temperature_all %>% 
  group_by(date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  #daily mean for each station
  summarise_at(vars(matches("^t_ws[1-9]|^t_ws1[0-8]$")), list(Daily_temp = ~mean(., na.rm = TRUE)))
 

rh_daily <- relative_humidity_all %>% 
  group_by(date, Year, Month, Day) %>% # here we left column with hour out to calculate daily mean
  #daily mean for each station
  summarise_at(vars(matches("^rh_ws[1-9]|^rh_ws1[0-8]$")), list(Daily_temp = ~mean(., na.rm = TRUE)))

```

```{r}
#save datasets
write.csv(load_daily,file=here("Data","Processed","Daily_Load.csv"))
write.csv(temp_daily,file=here("Data","Processed","Daily_Temp.csv"))
write.csv(rh_daily,file=here("Data","Processed","Daily_Relative_Humidity.csv"))
```

## CREATE A TIME SERIES OBJECT

```{r}
#load time series object
ts_load_daily <- msts(load_daily$Daily_mean_load, #daily data frame mean
                           seasonal.periods =c(7,365.25), #seasonal periods
                           start=c(2005,1,1))
```

```{r}
#decomposition of daily data
ts_load_daily %>% mstl() %>%
  autoplot()
```

## CREATING TEST AND TRAINING DATASETS (YEAR AND MONTH)

```{r}
#training and test datasets

#create a subset for training purpose (try forecasting for one month!)
n_for = 365
ts_daily_train <- subset(ts_load_daily,
                                   end = length(ts_load_daily)-n_for)

#create a subset for testing purpose
ts_daily_test <- subset(ts_load_daily,
                                   start = length(ts_load_daily)-n_for)

#test is just a month
ts_daily_train_month <- subset(ts_load_daily,
                                   end = length(ts_load_daily)-30)

#create a subset for testing purpose
ts_daily_test_month <- subset(ts_load_daily,
                                   start = length(ts_load_daily)-30)
```

```{r}
#plotting these test and train data
autoplot(ts_daily_train)
autoplot(ts_daily_test)
```

## FITTING AND FORECASTING MODELS

### ETS
```{r}
#Fit and forecast STL + ETS model to data with a year of holdout data
ETS_fit <-  stlf(ts_daily_train,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Load")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Active Load") +
  ggtitle("ETS with year of holdout")

#trying with just the month test set as opposed to year

ETS_fit_2 <-  stlf(ts_daily_train_month,h=30)

#Plot foresting results
autoplot(ETS_fit_2) + ylab("Load")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ETS_fit_2, series="STL + ETS",PI=FALSE) +
  ylab("Active Load") +
  ggtitle("ETS with month of holdout")
```

```{r}
ETS_scores <- accuracy(ETS_fit$mean,ts_daily_test)
ETS_scores

ETS_scores_2 <- accuracy(ETS_fit_2$mean,ts_daily_test_month)
ETS_scores_2
```

```{r}
# adding results from ETS_fit to submission template (year holdout)
submission_ETS <- read_csv("output/submission_template.csv", 
    col_types = cols(load = col_number()))

submission_ETS$load <- ETS_fit$fitted[1977:2007]

#creating .csv output
write.csv(submission_ETS,file=here("output","Submission1_EK_JW.csv"),
          row.names = F)

# adding results from ETS_fit2 to submission template (month holdout)
submission_ETS2 <- read_csv("output/submission_template.csv", 
    col_types = cols(load = col_number()))

submission_ETS2$load <- ETS_fit_2$fitted[2312:2342]

#creating .csv output
write.csv(submission_ETS2,file=here("output","Submission5_EK_JW.csv"),
          row.names = F)
```

### Arima and Fourier
```{r}
ARIMA_Four_fit <- auto.arima(ts_daily_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_daily_train, 
                                          K=c(2,4))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_daily_train,
                                        K=c(2,4),
                                        h=365), h=365) 
#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Load") + ggtitle("ARIMA w Fourier (2,4)")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Load")

```

```{r}
#Model 2: ARIMA + Fourier 
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_daily_test)
ARIMA_scores
```

```{r}
# adding results from arima1 to submission template (month holdout)
submission_arima1 <- read_csv("output/submission_template.csv", 
    col_types = cols(load = col_number()))
submission_arima1$load <- ARIMA_Four_for$fitted[1977:2007]

#creating .csv output
write.csv(submission_arima1,file=here("output","Submission6_EK_JW.csv"),
          row.names = F)
```

###  ARIMA w (2,4) Fourier and Exogenous variables 

```{r exogenous variables , echo=TRUE, message=FALSE, warning=FALSE}
# load exogenous variables
raw_temp <- read.csv(here('Data','Processed','Daily_Temp.csv'))
raw_temp <- raw_temp %>% 
  drop_na()

raw_humidity <- read.csv(here('Data','Processed','Daily_Relative_Humidity.csv'))

avg_temp <- raw_temp %>% 
  mutate(avgTemp = rowMeans(select(., 6:33)))
```

```{r exogenous variables test and train, avg temperature}
#ts object of exogenous variables 
ts_avgtemp <- msts(avg_temp$avgTemp, 
                  start=c(2005,1,1),
                  seasonal.periods =c(7,365.25))

#External regressors test and train
temp_avg_monthly_train <- subset(ts_avgtemp,
                                   end = length(ts_load_daily)-30)

temp_avg_monthly_test <- subset(ts_avgtemp,
                                   start = length(ts_load_daily)-30)

temp_avg_for <- forecast(ts_avgtemp, h=31)
```

```{r}
# Generate Fourier series components
fourier_components <- fourier(ts_daily_train_month, K=c(2,4))
fourier_for <- fourier(ts_daily_train_month, K=c(2,4), h=31)

# Combine Fourier components with temperature data
regressors <- cbind(as.matrix(data.frame(fourier_components)), 
                    "temp" = temp_avg_monthly_train)

regressors_for <- cbind(as.matrix(data.frame(fourier_for)), 
                    "temp" = temp_avg_monthly_test)

ARIMA_Four_fit_temp <- auto.arima(ts_daily_train_month, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=regressors)

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for_temp <- forecast(ARIMA_Four_fit_temp,
                           xreg=regressors_for) 
#Plot foresting results
autoplot(ARIMA_Four_for_temp) + ylab("Load") + ggtitle("ARIMA w Fourier (2,4) and avg temp")

#Plot model + observed data
autoplot(ts_load_daily) +
  autolayer(ARIMA_Four_for_temp, series="ARIMA_FOURIER_Temp",PI=FALSE) +
  ylab("Load")

```

```{r}
#Model 2: ARIMA + Fourier 
ARIMA_temp_scores <- accuracy(ARIMA_Four_for_temp$mean,ts_daily_test_month)
ARIMA_temp_scores
```

```{r}
# adding results from ARIMA_Four_for_temp to submission template (month holdout)
submission_arima2 <- read_csv("output/submission_template.csv", 
    col_types = cols(load = col_number()))
submission_arima2$load <- ARIMA_Four_for_temp$fitted[1977:2007]

#creating .csv output
write.csv(submission_arima2,file=here("output","Submission7_EK_JW.csv"),
          row.names = F)
```

other ideas:
- average for monthly values to reduce run time, use humidity, average results from best performing models to make an 'ensemble method'